{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing Heatmap Experiments\n",
    "The goal of this notebook is to make it very easy for reviewers and readers of the accompanying paper to reproduce experimental results and make minor modifications, in order to convince themselves the experimental methods are sound, the results valid, and the conclusions appropriate.\n",
    "\n",
    "In particular, this file contains the code to build the heatmaps seen in figures TODO and their corresponding isolines. Familiarity with the supplied repo is recommended: there are two tutorial notebooks that serve as a primer. \n",
    "\n",
    "Recall that the goal of this experiment is to show two (equivalent) statements:\n",
    "\n",
    "_Amongst the set of combination threat models with the same adversarial strength, the threat model that produces adversarial examples of minimal perceptual distance (according to quantifiable perceptual metrics) utilizes both additive and flow attacks_ \n",
    "\n",
    "And the 'dual' of the above statment:\n",
    "\n",
    "_Amongst the set of combination threat models that produce adversarial examples of equivalent perceptual distance (according to quantifiable perceptual metrics), the threat model that produces attacks most likely to fool a classifier is a combination of both additive and flow attacks_\n",
    "\n",
    "## Contents\n",
    "- Preliminaries \n",
    "- Building Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries \n",
    "Setting up models, attacks, etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTERNAL LIBRARY IMPORTS\n",
    "import numpy as np \n",
    "import scipy \n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch # Need torch version 0.3 or 0.4\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "assert torch.__version__[:3] in ['0.3', '0.4', '0.5']\n",
    "\n",
    "use_gpu = torch.cuda.is_available() # STRONGLY RECOMMENDED THAT YOU RUN CODE ON GPU MACHINE\n",
    "print(\"Using GPU? \" + str(use_gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT BLOCK\n",
    "# (here we do things so relative imports work )\n",
    "# Universal import block \n",
    "# Block to get the relative imports working \n",
    "import os\n",
    "import sys \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import config\n",
    "\n",
    "import prebuilt_loss_functions as plf\n",
    "import loss_functions as lf \n",
    "import utils.pytorch_utils as utils\n",
    "import utils.image_utils as img_utils\n",
    "import cifar10.cifar_loader as cifar_loader\n",
    "import cifar10.cifar_resnets as cifar_resnets\n",
    "import adversarial_attacks as aa\n",
    "import adversarial_training as advtrain\n",
    "import adversarial_evaluation as adveval\n",
    "import utils.checkpoints as checkpoints\n",
    "import adversarial_perturbations as ap \n",
    "import adversarial_attacks_refactor as aar\n",
    "import spatial_transformers as st\n",
    "import prebuilt_attacks as pa \n",
    "import utils.experiment_utils as eu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Initialize the dataLoader, classifier, and normalizer \"\"\"\n",
    "use_gpu = torch.cuda.is_available()\n",
    "classifier_net = cifar_loader.load_pretrained_cifar_resnet(flavor=32,\n",
    "                                                           use_gpu=use_gpu)\n",
    "EXPERIMENT_NAME = 'linfStadv'\n",
    "defended_state_dict_file = checkpoints.params_to_filename(EXPERIMENT_NAME, 'resnet32')[-1]\n",
    "print \"Loading %s params into resnet32\" % defended_state_dict_file \n",
    "classifier_net = checkpoints.load_state_dict_from_filename(defended_state_dict_file, classifier_net)    \n",
    "classifier_net.eval()\n",
    "\n",
    "train_loader = cifar_loader.load_cifar_data('train', normalize=False, \n",
    "                                            batch_size=128, use_gpu=use_gpu)\n",
    "val_loader = cifar_loader.load_cifar_data('val', normalize=False, \n",
    "                                          batch_size=32, use_gpu=use_gpu, \n",
    "                                           shuffle=False)\n",
    "cifar_normer = utils.DifferentiableNormalize(mean=config.CIFAR10_MEANS,\n",
    "                                             std=config.CIFAR10_STDS)\n",
    "examples, labels = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Code to build a heatmap as a dictionary mapping (row, col) indices to \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def create_heatmap_v2(classifier_net, discretization=5, stadv_limit=1.0/64, linf_limit=8.0/255.0,\n",
    "                   num_minibatches=10):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        classifier_net: the network to attack\n",
    "        discretization: how many equally spaced intervals between the limits should we try?\n",
    "        stadv_limit: maximum allowable stadv perturbation\n",
    "        linf_limit: maximum allowable linf_perturbation\n",
    "    \"\"\"\n",
    "    stadv_inc = stadv_limit / discretization\n",
    "    linf_inc = linf_limit / discretization\n",
    "    data_out = []\n",
    "    attack_ensemble = {} \n",
    "    for i in range(discretization + 1):\n",
    "        for j in range(discretization + 1):\n",
    "            current_stadv_limit = stadv_inc * (i)\n",
    "            current_linf_limit = linf_inc * (j)\n",
    "            attack_ensemble[(i, j)] = pa.build_delta_stadv_pgd(classifier_net, cifar_normer, \n",
    "                                                               delta_bound=current_linf_limit, \n",
    "                                                               flow_bound=current_stadv_limit, \n",
    "                                                               output='eval')\n",
    "    eval_obj = adveval.AdversarialEvaluation(classifier_net, cifar_normer, use_gpu=use_gpu)\n",
    "    eval_output = eval_obj.evaluate_ensemble(val_loader, attack_ensemble, verbose=True, \n",
    "                                             num_minibatches=num_minibatches)\n",
    "    \n",
    "    return eval_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Code to display heatmap \"\"\"\n",
    "def display_heatmap(eval_output, val_to_show, flow_bound, linf_bound, discretization, normalize=False,\n",
    "                    levels=None, scale=(10,10), no_title=False):\n",
    "    \"\"\" Plots the heatmap     \n",
    "    \"\"\"\n",
    "    assert val_to_show in ['lpips', 'strength']\n",
    "    preprocess = lambda x: x\n",
    "    if val_to_show == 'strength':\n",
    "        val_to_show = 'top1'\n",
    "        #preprocess = lambda x: 1 - x\n",
    "        \n",
    "    disc = discretization    \n",
    "    heatmap = np.zeros((disc + 1, disc + 1))\n",
    "    for k, val in eval_output.items():\n",
    "        if k == 'ground':\n",
    "            continue \n",
    "        i, j = k\n",
    "        heatmap[i][j] = preprocess(val.results[val_to_show].avg)\n",
    "        \n",
    "    vmax = 1.0\n",
    "    if val_to_show == 'lpips':        \n",
    "        heatmap = (torch.Tensor(heatmap) * 1000).numpy()\n",
    "        vmax = np.max(heatmap)\n",
    "        plot_title = \"LPIPS Distance\"\n",
    "    else:    \n",
    "        plot_title = \"Attack Strength\"\n",
    "    if normalize:\n",
    "        vmax = 1.0\n",
    "        heatmap = heatmap / np.max(heatmap)  \n",
    "        plot_title = \"(normalized) \" + plot_title\n",
    "        \n",
    "    plt.figure(figsize=scale, dpi=80, facecolor='w', edgecolor='k')    \n",
    "    \n",
    "    if not no_title:\n",
    "        plt.title(plot_title, fontsize=32)\n",
    "    plt.xlabel(r\"Delta bound\", fontsize=32)\n",
    "    plt.ylabel(r\"Flow bound ($\\times 64$)\", fontsize=32)\n",
    "    \n",
    "    to_show_delta = linf_bound * 255.0\n",
    "    to_show_flow = flow_bound * 64\n",
    "    x = plt.contourf([to_show_delta / disc * _ for _ in range(disc + 1)], \n",
    "                 [to_show_flow / disc * _ for _ in range(disc + 1)], \n",
    "                 heatmap, vmin=0, vmax=vmax, xunits=2, levels=levels)\n",
    "    return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER INPUT TO RUN EXPERIMENTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "First you'll want to set:\n",
    "- the flow/additive linf bounds\n",
    "- how fine the mesh is\n",
    "- how many minibatches you want to evaluate on per mesh point\n",
    "\n",
    "And then build up the heatmap for all of these meshpoints\n",
    "\n",
    "\"\"\"\n",
    "FLOW_BOUND = 1.0 / 64 # THESE ARE TYPICALLY CONSIDERED AS X/64.0 FOR 32x32 IMAGES\n",
    "\n",
    "LINF_BOUND = 8.0 / 255.0 # THESE ARE TYPICALLY CONSIDERED AS X/255.0 FOR 8-BIT RGB IMAGES\n",
    "\n",
    "DISCRETIZATION = 10 # THERE ARE (discretization + 1)**2 MESHPOINTS\n",
    "\n",
    "NUM_MINIBATCHES = 10 # ~1/4 OF CIFAR EVAL SET, FOR MORE INSTANT GRATIFICATION\n",
    "\n",
    "\n",
    "# This next step takes some time, so only do it once\n",
    "heatmap_eval_output = create_heatmap_v2(classifier_net, \n",
    "                                     discretization=DISCRETIZATION,\n",
    "                                     stadv_limit=FLOW_BOUND, \n",
    "                                     linf_limit=LINF_BOUND, \n",
    "                                     num_minibatches=NUM_MINIBATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" And with the eval output built, you can display heatmap. \n",
    "    OPTIONS TO TOGGLE HERE: \n",
    "    \n",
    "    val_to_show: ['strength', 'lpips'] : does the heatmap represent strength or LPIPS distance \n",
    "    normalize : [True, False] : do we normalize the values such that the max value such that it is 1.0?    \n",
    "\"\"\"\n",
    "\n",
    "VAL_TO_SHOW = 'strength' # must be one of 'strength', 'lpips'\n",
    "\n",
    "normalize = (VAL_TO_SHOW == 'lpips') # normalize only lpips values by default\n",
    "\n",
    "x = display_heatmap(heatmap_eval_output, VAL_TO_SHOW, FLOW_BOUND, LINF_BOUND, DISCRETIZATION, normalize=normalize,\n",
    "                    levels = [0.05 * i for i in xrange(22)])\n",
    "y = display_heatmap(heatmap_eval_output, 'lpips', FLOW_BOUND, LINF_BOUND, DISCRETIZATION, normalize=False,\n",
    "                    levels=[0.1 * i for i in xrange(50)])\n",
    "\n",
    "#x.collections[1].get_paths()[0].vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note on interpreting these plots\n",
    "Recall the statements we wish to prop up with experimental data:\n",
    "\n",
    "_Amongst the set of combination threat models with the same adversarial strength, the threat model that produces adversarial examples of minimal perceptual distance (according to quantifiable perceptual metrics) utilizes both additive and flow attacks_ \n",
    "\n",
    "and \n",
    "\n",
    "_Amongst the set of combination threat models that produce adversarial examples of equivalent perceptual distance (according to quantifiable perceptual metrics), the threat model that produces attacks most likely to fool a classifier is a combination of both additive and flow attacks_\n",
    "\n",
    "If these statements were true, then one would expect the plots of the isolines of the LPIPS plot to be 'more concave' than the isolines of the strength plot. Verify that this is occurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
